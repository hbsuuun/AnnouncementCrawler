"""
PDFå…¬å‘Šæ–‡æœ¬æå–è„šæœ¬
å°† downloads/ ç›®å½•ä¸‹çš„ PDF æå–ä¸º txt/md æ–‡ä»¶åˆ° processed/ ç›®å½•
"""
import os
import re
from pathlib import Path
from datetime import datetime
import pdfplumber

def extract_text_from_pdf(pdf_path: str) -> str:
    """ä»PDFä¸­æå–æ–‡æœ¬"""
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n\n"
    except Exception as e:
        print(f"âŒ æå–å¤±è´¥: {pdf_path} - {e}")
    return text

def sanitize_filename(filename: str) -> str:
    """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦"""
    illegal_chars = r'[<>:"/\\|?*]'
    return re.sub(illegal_chars, '_', filename)

def convert_to_markdown(text: str, pdf_path: str, output_dir: Path) -> str:
    """å°†æ–‡æœ¬è½¬æ¢ä¸ºMarkdownæ ¼å¼"""
    # ä»PDFè·¯å¾„æå–ä¿¡æ¯
    pdf_name = Path(pdf_path).stem
    # ä¿®å¤ï¼šè½¬ä¸ºç»å¯¹è·¯å¾„åå†è®¡ç®—ç›¸å¯¹è·¯å¾„
    pdf_absolute = Path(pdf_path).resolve()
    pdf_relative = pdf_absolute.relative_to(Path.cwd())
    
    # æ¸…ç†æ–‡æœ¬ä¸­çš„å¤šä½™ç©ºè¡Œ
    lines = text.split('\n')
    cleaned_lines = []
    for i, line in enumerate(lines):
        # ç§»é™¤é¡µçœ‰é¡µè„šï¼ˆå¸¸è§çš„é¡µç æ ¼å¼ï¼‰
        if re.match(r'^\s*\d+\s*$', line.strip()):
            continue
        # ç§»é™¤å•è¡Œçš„ç ´æŠ˜å·
        if re.match(r'^[-â”€]{10,}$', line.strip()):
            continue
        cleaned_lines.append(line)
    
    text_clean = '\n'.join(cleaned_lines)
    
    # æ„å»ºMarkdown
    md_content = f"""---
title: {pdf_name}
source: {pdf_relative}
extracted_at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
---

# {pdf_name}

{text_clean}
"""
    return md_content

def process_pdf(pdf_path: Path, output_dir: Path, use_markdown: bool = True):
    """å¤„ç†å•ä¸ªPDFæ–‡ä»¶"""
    # ä¿®å¤ï¼šè½¬ä¸ºç»å¯¹è·¯å¾„
    pdf_path = pdf_path.resolve()
    
    # æ„å»ºè¾“å‡ºè·¯å¾„
    relative_path = pdf_path.relative_to(Path.cwd())
    relative_dir = relative_path.parent
    
    # æ„å»ºç›®æ ‡è·¯å¾„
    if use_markdown:
        output_subdir = output_dir / "markdown" / relative_dir
        output_path = output_subdir / f"{pdf_path.stem}.md"
    else:
        output_subdir = output_dir / "text" / relative_dir
        output_path = output_subdir / f"{pdf_path.stem}.txt"
    
    # åˆ›å»ºç›®å½•
    output_subdir.mkdir(parents=True, exist_ok=True)
    
    # æå–æ–‡æœ¬
    print(f"ğŸ“„ å¤„ç†: {pdf_path}")
    text = extract_text_from_pdf(str(pdf_path))
    
    if not text.strip():
        print(f"   âš ï¸ è­¦å‘Š: {pdf_path} æå–å†…å®¹ä¸ºç©º")
        return False
    
    # ä¿å­˜
    if use_markdown:
        content = convert_to_markdown(text, str(pdf_path), output_dir)
        output_path = output_subdir / f"{pdf_path.stem}.md"
    else:
        content = text
        output_path = output_subdir / f"{pdf_path.stem}.txt"
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"   âœ… å·²ä¿å­˜: {output_path}")
    return True

def main():
    """ä¸»å‡½æ•°"""
    downloads_dir = Path("downloads")
    output_dir = Path("processed")
    
    if not downloads_dir.exists():
        print("âŒ downloads ç›®å½•ä¸å­˜åœ¨")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰PDFæ–‡ä»¶
    pdf_files = list(downloads_dir.rglob("*.pdf"))
    
    if not pdf_files:
        print("âŒ æœªæ‰¾åˆ°PDFæ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
    print("=" * 50)
    
    # å¤„ç†æ¯ä¸ªPDF
    success = 0
    for pdf_path in pdf_files:
        if process_pdf(pdf_path, output_dir, use_markdown=True):
            success += 1
    
    print("=" * 50)
    print(f"âœ… å®Œæˆ: {success}/{len(pdf_files)} ä¸ªæ–‡ä»¶å¤„ç†æˆåŠŸ")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}/(markdown|text)/")

if __name__ == "__main__":
    main()